{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Improving the Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will improve the search index and query functions from the previous assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data and Defining Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is copied from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, bz2, re\n",
    "from collections import namedtuple, defaultdict, Counter\n",
    "from IPython.display import display, HTML\n",
    "from math import log10, sqrt\n",
    "\n",
    "Summaries_file = 'data/allergy_Summaries.pkl.bz2'\n",
    "Abstracts_file = 'data/allergy_Abstracts.pkl.bz2'\n",
    "\n",
    "Summaries = pickle.load( bz2.BZ2File( Summaries_file, 'rb' ) )\n",
    "Abstracts = pickle.load( bz2.BZ2File( Abstracts_file, 'rb' ) )\n",
    "\n",
    "paper = namedtuple( 'paper', ['title', 'authors', 'year', 'doi'] )\n",
    "for (id, paper_info) in Summaries.items():\n",
    "    Summaries[id] = paper( *paper_info )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Function that tokenizes a string in a rather naive way. Can be extended later.\n",
    "    \"\"\"\n",
    "    return text.split(' ')\n",
    "\n",
    "def preprocess(tokens):\n",
    "    \"\"\"\n",
    "    Perform linguistic preprocessing on a list of tokens. Can be extended later.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        result.append(token.lower())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1038/nature12526>Type 2 innate lymphoid cells control eosinophil homeostasis.</a></strong><br>2013. Nussbaum JC, Van Dyken SJ, von Moltke J, Cheng LE, Mohapatra A, Molofsky AB, Thornton EE, Krummel MF, Chawla A, Liang HE, Locksley RM<br>[ID: 24037376]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1038/nature12526>Type 2 innate lymphoid cells control eosinophil homeostasis.</a></strong><br>2013. Nussbaum JC, Van Dyken SJ, von Moltke J, Cheng LE, Mohapatra A, Molofsky AB, Thornton EE, Krummel MF, Chawla A, Liang HE, Locksley RM<br><small><strong>Abstract:</strong> <em>Eosinophils are specialized myeloid cells associated with allergy and helminth infections. Blood eosinophils demonstrate circadian cycling, as described over 80 years ago, and are abundant in the healthy gastrointestinal tract. Although a cytokine, interleukin (IL)-5, and chemokines such as eotaxins mediate eosinophil development and survival, and tissue recruitment, respectively, the processes underlying the basal regulation of these signals remain unknown. Here we show that serum IL-5 levels are maintained by long-lived type 2 innate lymphoid cells (ILC2) resident in peripheral tissues. ILC2 cells secrete IL-5 constitutively and are induced to co-express IL-13 during type 2 inflammation, resulting in localized eotaxin production and eosinophil accumulation. In the small intestine where eosinophils and eotaxin are constitutive, ILC2 cells co-express IL-5 and IL-13; this co-expression is enhanced after caloric intake. The circadian synchronizer vasoactive intestinal peptide also stimulates ILC2 cells through the VPAC2 receptor to release IL-5, linking eosinophil levels with metabolic cycling. Tissue ILC2 cells regulate basal eosinophilopoiesis and tissue eosinophil accumulation through constitutive and stimulated cytokine expression, and this dissociated regulation can be tuned by nutrient intake and central circadian rhythms. </em></small><br>[ID: 24037376]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_summary( id, show_abstract=False, show_id=True, extra_text='' ):\n",
    "    \"\"\"\n",
    "    Function for printing a paper's summary through IPython's Rich Display System.\n",
    "    Trims long author lists, and adds a link to the paper's DOI (when available).\n",
    "    \"\"\"\n",
    "    s = Summaries[id]\n",
    "    lines = []\n",
    "    title = s.title\n",
    "    if s.doi != '':\n",
    "        title = '<a href=http://dx.doi.org/{:s}>{:s}</a>'.format(s.doi, title)\n",
    "    title = '<strong>' + title + '</strong>'\n",
    "    lines.append(title)\n",
    "    authors = ', '.join( s.authors[:20] ) + ('' if len(s.authors) <= 20 else ', ...')\n",
    "    lines.append(str(s.year) + '. ' + authors)\n",
    "    if (show_abstract):\n",
    "        lines.append('<small><strong>Abstract:</strong> <em>{:s}</em></small>'.format(Abstracts[id]))\n",
    "    if (show_id):\n",
    "        lines.append('[ID: {:d}]'.format(id))\n",
    "    if (extra_text != ''):\n",
    "         lines.append(extra_text)\n",
    "    display( HTML('<br>'.join(lines)) )\n",
    "    \n",
    "display_summary(24037376)\n",
    "display_summary(24037376, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{16513592, 18706961, 15504455}\n"
     ]
    }
   ],
   "source": [
    "inverted_index = defaultdict(set)\n",
    "\n",
    "for (id, abstract) in Abstracts.items():\n",
    "    for term in preprocess(tokenize(abstract)):\n",
    "        inverted_index[term].add(id)\n",
    "        \n",
    "print(inverted_index['amsterdam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could see from the results of the last assignment, our simple index doesn't handle punctuation and the difference between singular and plural versions of the same word very well. We won't go much into the details of tokenization and linguistic analysis here, because we also want to focus on scoring and ranking below. Therefore, we are using an existing library for tokenizatoin and stemming, namely the NLTK package. The following line will install NLTK if necessary (or you have to follow [these instructions](http://www.nltk.org/install.html) if that doesn't work):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\polinab\\appdata\\roaming\\python\\python37\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\polinab\\miniconda3\\lib\\site-packages (from nltk) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install --user nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT TEXT:\n",
      "  Good muffins cost $3.88\n",
      "in New York.  Please buy me two of them.\n",
      "\n",
      "Thanks.\n",
      "TOKENIZE:  ['Good', 'muffins', 'cost', '$3.88\\nin', 'New', 'York.', '', 'Please', 'buy', 'me', 'two', 'of', 'them.\\n\\nThanks.']\n",
      "WORD TOKENIZE:  ['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\polinab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "stemmer = EnglishStemmer()\n",
    "\n",
    "s = '''Good muffins cost $3.88\\nin New York.  Please buy me two of them.\\n\\nThanks.'''\n",
    "\n",
    "print('INPUT TEXT:\\n ', s)\n",
    "\n",
    "print('TOKENIZE: ', tokenize(s))\n",
    "print('WORD TOKENIZE: ', word_tokenize(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem(\"processes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important method to improve our search results is to rank them, which can be done by calculating a score for each document based on the matching terms from the query. One such scoring method is *tf-idf*, which comes with several variants, as explained in the lecture slides.\n",
    "\n",
    "In order to quickly calculate the scores for a term/document combination, we'll need quick access to a couple of things:\n",
    "\n",
    "- tf(t,d): How often does a term occur in a document\n",
    "- df(t): In how many documents does a term occur\n",
    "- num_documents: The number of documents in our index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "tf_matrix = defaultdict(Counter)\n",
    "\n",
    "for (doc_id, abstract) in Abstracts.items():\n",
    "    tokens = preprocess(tokenize(abstract))\n",
    "#     print(doc_id)\n",
    "    tf_matrix[doc_id] = Counter(tokens)\n",
    "  \n",
    "# print(tf_matrix[16513592])\n",
    "\n",
    "def tf(t,d):\n",
    "#     print(t)\n",
    "#     print(d)\n",
    "    return float(tf_matrix[d][t])\n",
    "\n",
    "print(tf('amsterdam',16513592))\n",
    "\n",
    "def df(t):\n",
    "    return float(len(inverted_index[t]))\n",
    "\n",
    "num_documents = float(len(Abstracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test these functions with some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "3.0\n",
      "73679.0\n"
     ]
    }
   ],
   "source": [
    "print(tf('amsterdam', 16513592))\n",
    "print(df('amsterdam'))\n",
    "print(num_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these helper functions, we can now easily calculate the _tf-idf_ weights of a term in a document by implementing the weighting formula from the slides, which you will do in the assignments below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your name:** Polina Boneva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Implement in the code block below the `smarter_tokenize` function using NLTK's function for tokenization, and the `smarter_preprocess` function to perform stemming in addition to case normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'buy', 'mani', 'book', ',', 'some', 'about', 'i.r.', ',', 'for', 'less', 'than', '$', '1.50', '!']\n"
     ]
    }
   ],
   "source": [
    "# Smarter linguistic processing\n",
    "def smarter_tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def smarter_preprocess(tokens):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        result.append(stemmer.stem(token))\n",
    "    return result\n",
    "\n",
    "# To test it:\n",
    "print(smarter_preprocess(smarter_tokenize(\"He buys many books, some about I.R., for less than $1.50!\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make a smarter index based on these functions. For practical purposes, the code below generates the smarter index on a subset of the data, as generating an index with stemming on the entire set would take too much time. (You don't need to change or add anything in the code block below. Just leave it as it is.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below, we create our smarter index (based on a subset of the documents for demonstration purposes)\n",
    "smarter_index = defaultdict(set)\n",
    "\n",
    "# Here we define the subset (somewhat arbitrary):\n",
    "subset_of_ids = set(key for key in Abstracts.keys() if 24000000 <= key < 25000000)\n",
    "subset_of_abstracts = ((key, Abstracts[key]) for key in subset_of_ids)\n",
    "\n",
    "# Building our smarter index:\n",
    "for (id, abstract) in subset_of_abstracts:\n",
    "    for term in smarter_preprocess(smarter_tokenize(abstract)):\n",
    "        smarter_index[term].add(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the `smarter_and_query` function, based on the two functions `smarter_tokenize` and `smarter_preprocess` you defined above and accessing our new index `smarter_index`. You can start from the code for `and_query` from the last assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{24037376}\n",
      "{24037376, 24600450, 24645804, 24486607}\n"
     ]
    }
   ],
   "source": [
    "# Smarter and_query based on the smarter tokenize and preprocess functions\n",
    "def smarter_and_query(query):\n",
    "    them_words = smarter_preprocess(smarter_tokenize(query))\n",
    "    full_set_of_docs = [smarter_index[word] for word in them_words]\n",
    "    return set.intersection(*full_set_of_docs)\n",
    "    \n",
    "print(smarter_and_query('resident in peripheral tissues'))\n",
    "print(smarter_and_query('eosinophil signal inflammation'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Run the queries \"eosinophil signal inflammation\" and \"eosinophil rhythm\" with the new `smarter_and_query` function from task 1. Do they return paper *24037376* (this is our exemplary paper from the last assignment)? For each of the two example queries, what do our new smarter functions specifically contribute to the result (as compared to our previous naive implementations for tokenization and preprocessing)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{24037376, 24600450, 24645804, 24486607}\n",
      "{24037376}\n"
     ]
    }
   ],
   "source": [
    "print(smarter_and_query('eosinophil signal inflammation'))\n",
    "print(smarter_and_query('eosinophil rhythm'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** The smarter_and_query makes use of the smarter_index we have created, instead of the inverted_index used in the previous assignment, which was used by the normal and_query. The smarter_index is smarter than the inverted_index because it uses stemmed versions of the terms in the query to list all relevant documents. The relevant documents are also found by using the stemmed version of all terms in the document, thus the smarter_index provides us with lists of documents which contain the roots or base-words of the words we are looking up, which are also pre-processed the exact same way before they are looked up in the smarter_index. Thus, the smarter_and_query would give the doc with id 24037376 when we are looking for 'signal' even though the exact word in the document is 'signals' because the smarter_index holds the stemmed version of the word 'signals', meaning 'signal' in this case. The stemmed version of it could've been 'signa' and then both the query term we are looking up would be 'signa', and the indexed word would be 'signa'. The smarter way to process words allows a broader spectrum of results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Now we move to a different subject and use our old index again. That is, we **don't** use the smarter functions defined above for tasks 3 to 5!\n",
    "\n",
    "Create a function `tfidf(t,d)` that returns the tf-idf score of term `t` in document `d` by using `tf(t,d)`, `df(t)` and `num_documents` as defined above. To do this, first implement a function `idf(t)` to calculate the inverse document frequency, and then use this function to calculate the full tf-idf. Use the _add-one-smoothing_ version of idf, so we don't run into problems with terms that don't appear in the collection at all. The relevant formulas can be found on the lecture slides. Use tf-idf with plain (non-logarithmic) term frequency, as applied by scoring variant `ntn`. Test your function with the examples shown below. You can use the `log10(n)` function to calculate the base 10 logarithm.\n",
    "\n",
    "Again, use our old (non-smart) index for this task and the tasks below, and **not** the functions defined in tasks 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.19659157248719\n",
      "3.985735598978652\n",
      "0.7198241129610893\n"
     ]
    }
   ],
   "source": [
    "def idf(t):\n",
    "    doc_freq = df(t)\n",
    "    return log10((num_documents + 1) / (doc_freq + 1))\n",
    "\n",
    "def tfidf(t,d):\n",
    "    return tf(t, d)*idf(t)\n",
    "\n",
    "print(tfidf('ilc2', 24037376))\n",
    "print(tfidf('regulation', 24037376))\n",
    "print(tfidf('with', 24037376))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Create a function `query_ntn(query_string)`, which accepts as input a single query string of one or more words, and returns or prints a list of (up to) 10 best matching documents, along with their score. Use _tf-idf_ to calculate document scores based on the query, applying variant `ntn`, as above (see the formula for the `ntn` version of scoring on the lecture slides). Use an auxiliary function `score_ntn` to calculate the score. The results should be shown in descending order by score.\n",
    "\n",
    "You can start by copying your `or_query` function from assignment 2, then expand that to rank the results, making use of the `tfidf(t,d)` function you created above. Make sure to apply term weighting to the query terms too.\n",
    "\n",
    "Demonstrate your function by giving it the exemplary query string \"factors of food allergy for children\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(22375277, 31.870018900405626),\n",
       " (9949358, 29.134746906560608),\n",
       " (26022884, 29.056853832696227),\n",
       " (22221430, 28.99141174147007),\n",
       " (15138413, 28.881053385432732),\n",
       " (22450958, 28.63870260685852),\n",
       " (15121966, 27.59080762413563),\n",
       " (11132467, 27.419140400318838),\n",
       " (21535179, 27.380946765249128),\n",
       " (30918205, 26.86790890755561)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sortSecond(val): \n",
    "    return val[1]\n",
    "\n",
    "def or_query(q):\n",
    "    them_words = preprocess(tokenize(q))\n",
    "    full_set_docs = [inverted_index[word] for word in them_words]\n",
    "    return set.union(*full_set_docs)\n",
    "\n",
    "def score_ntn(query_words, doc_id):\n",
    "    them_words = preprocess(tokenize(query_words))\n",
    "    return sum([tfidf(term, doc_id) for term in them_words])\n",
    "\n",
    "def query_ntn(query_string):\n",
    "    docs_set = or_query(query_string)\n",
    "    doc_scores = [(doc_id, score_ntn(query_string, doc_id)) for doc_id in docs_set]\n",
    "    doc_scores.sort(key = sortSecond, reverse = True)\n",
    "    \n",
    "    return doc_scores[:10]\n",
    "        \n",
    "# Example query:\n",
    "query_ntn(\"factors of food allergy for children\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "In this last task, you should create a second version of the query function from Task 4, called `query_ntc`. This second version should use, as its name suggests, variant `ntc` instead of `ntn`, and therefore apply the cosine similarity measure, in addition to applying _tf-idf_. For this, consult the formula for variant `nnc` on the lecture slides and adopt it to include the _idf_ metric (that is, add the `t` element of `ntc`). (You can drop the square root of |q| in the formula, as indicated on the slides.) Again, make sure to apply term weighting to the query terms too.\n",
    "\n",
    "As a first step, we can calculate beforehand the length of all document vectors (because they don't depend on the query) for document vectors consisting of _tf-idf_ values. The code below does just that, assuming that you defined the function `tfidf(t,d)` above (don't change this code block, just run it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_length_values = defaultdict(int)\n",
    "\n",
    "for (doc_id, abstract) in Abstracts.items():\n",
    "    l = 0\n",
    "    for t in tf_matrix[doc_id].keys():\n",
    "        l += tfidf(t,doc_id) ** 2\n",
    "    tfidf_length_values[doc_id] = sqrt(l)\n",
    "\n",
    "def tfidf_length(d):\n",
    "    return tfidf_length_values[d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get the length of a document vector by calling `tfidf_length(d)`.\n",
    "\n",
    "Based on this, you can now implement `query_ntc` in the code block below. You should again first define an auxiliary function, called `score_ntc`. You can start by copy-pasting the code from Task 4.\n",
    "\n",
    "To output the results, use the provided `display_summary` function to make the output a bit more like the results page of a search engine. Lastly, demonstrate your `query_ntc` function with the same example query as above: \"factors of food allergy for children\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>[Prognoses of food allergy in infancy].</strong><br>2005. Wang NR, Li HQ<br>[ID: 16255859]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1111/apa.14391>The interplay between risk and preventive factors explains why some children develop allergies to certain foods and others show tolerance.</a></strong><br>2018. Remes S, Kulmala P<br>[ID: 29751365]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1016/j.jpeds.2014.06.003>Growth comparison in children with and without food allergies in 2 different demographic populations.</a></strong><br>2014. Mehta H, Ramesh M, Feuille E, Groetch M, Wang J<br>[ID: 25039044]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1590/s0034-89102012000500009>[Prevalence of asthma and risk factors associated: population based study in São Paulo, Southeastern Brazil, 2008-2009].</a></strong><br>2012. Sousa CA, César CL, Barros MB, Carandina L, Goldbaum M, Pereira JC<br>[ID: 23128259]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>[Prevalence of self-reported food allergy and food intolerance and their associated factors in 3 - 12 year-old children in 9 areas in China].</strong><br>2015. Zhang Y, Chen Y, Zhao A, Li H, Mu Z, Zhang Y, Wang P<br>[ID: 25997224]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1067/mai.2003.1463>Genetic susceptibility to food allergy is linked to differential TH2-TH1 responses in C3H/HeJ and BALB/c mice.</a></strong><br>2003. Morafo V, Srivastava K, Huang CK, Kleiner G, Lee SY, Sampson HA, Li AM<br>[ID: 12743580]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.2500/aap.2011.32.3481>Phenotypes of IgE-mediated food allergy in Turkish children.</a></strong><br>2011. Yavuz ST, Sahiner UM, Buyuktiryaki B, Soyer OU, Tuncer A, Sekerel BE, Kalayci O, Sackesen C<br>[ID: 22221430]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1016/j.jaci.2018.06.044>Cesarean delivery, preterm birth, and risk of food allergy: Nationwide Swedish cohort study of more than 1 million children.</a></strong><br>2018. Mitselou N, Hallberg J, Stephansson O, Almqvist C, Melén E, Ludvigsson JF<br>[ID: 30213656]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>[Food challenges in children with asthma].</strong><br>2007. Krogulska A, Wasowska-Królikowska K, Trzeźwińska B<br>[ID: 18051825]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Genetic and environmental risk factors for the development of food allergy.</strong><br>2005. Björkstén B<br>[ID: 15864084]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def score_ntc(query_words, doc_id):\n",
    "    them_words = preprocess(tokenize(query_words))\n",
    "    \n",
    "    score = sum( [(tfidf(term, doc_id) * idf(term)) for term in them_words] ) / tfidf_length(doc_id)\n",
    "    return score\n",
    "\n",
    "def query_ntc(query_string):\n",
    "    docs_set = or_query(query_string)\n",
    "\n",
    "    doc_scores = [(doc_id, score_ntc(query_string, doc_id)) for doc_id in docs_set]\n",
    "    doc_scores.sort(key = sortSecond, reverse = True)\n",
    "    \n",
    "    for (doc_id, score) in doc_scores[:10]:\n",
    "        display_summary(doc_id)\n",
    "\n",
    "\n",
    "query_ntc(\"factors of food allergy for children\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the answers to the assignment via Canvas as a modified version of this Notebook file (file with `.ipynb` extension) that includes your code and your answers.\n",
    "\n",
    "Before submitting, restart the kernel and re-run the complete code (**Kernel > Restart & Run All**), and then check whether your assignment code still works as expected.\n",
    "\n",
    "Don't forget to add your name, and remember that the assignments have to be done individually and group submissions are **not allowed**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
